# 计算机网络

## TCP/IP模型（四层模型）

应用层  | 传输层(TCP) 网络层(IP) | 网络接口层

- **应用(程序)层**，为用户提供网络服务。它直接与用户应用程序交互，处理应用程序之间的通信细节。支持 HTTP、HTTPS、SMTP 、DNS、CDN等最终用户进程。数据单元通常称为消息或数据。

- **传输层**，提供端到端（主机到主机或进程到进程）的可靠或不可靠的数据传输服务。处理主机到主机的通信（TCP：面向连接的协议，三次握手四次挥手，具有可靠传输、UDP：无连接的协议，不可靠的传输）

- **网络层**，负责在源主机和目标主机之间选择最佳路径来传输数据包（也称为分组），实现网络互连和路由选择。作用是逻辑寻址（IP地址）、路由选择、数据包分片、网络互连。经典协议：IP：IPV4/IPV6 可靠性由TCP保证。
- **网络接口层**，负责在物理网络中（如一个局域网内）传输数据帧 (Frame)。它处理与物理介质（如电缆、光纤、无线信号）相关的细节，以及如何在相邻节点之间可靠地传输数据。作用如物理寻址（MAC地址：唯一的物理地址用于设备标识）。经典协议：以太网，Wi-Fi。

## 数据在TCP/IP模型中的封装与解封装

发送方：

应用层（产生数据/消息）

 传输层（数据分段，添加TCP/UDP头部：端口号等，形成TCP/UDP数据段）

 网络层（为传输层的数据段加上IP头部：IP地址等，形成IP数据包）

 网络接口层（为IP数据包添加帧头部和尾部：MAC地址等，形成数据帧，转换为比特流在物理介质上传输）

接收方：

网络接口层（从物理介质接受比特流，组装成数据帧，检查MAC地址和校验和，去掉帧头帧尾，将IP数据包向上传给网络层）

网络层（检查IP头部，根据IP地址判断是否是自己的数据包，去掉IP头部，将数据段上传给传输层）

传输层（根据TCP/UDP头部的端口号 将数据交给相应的应用程序进程，进行数据重组：TCP或直接交付:UDP，去掉TCP/UDP头部）

应用层（接收数据）

## 应用层

### HTTP报文有哪些部分

![image-20250506183304758](C:\Users\11965\Documents\八股\计算机网络.assets\image-20250506183304758.png)

```json
HTTP请求报文结构：
<方法> <请求目标> <HTTP版本>  (请求行)
<头部名称1>: <头部值1>
<头部名称2>: <头部值2>
...
<头部名称N>: <头部值N>
                                    (空行 - CRLF)
<可选的请求主体>
```

```json
HTTP响应报文结构:
<HTTP版本> <状态码> <原因短语>  (状态行)
<头部名称1>: <头部值1>
<头部名称2>: <头部值2>
...
<头部名称N>: <头部值N>
                                    (空行 - CRLF)
<可选的响应主体>
```

**请求报文：**

- 请求行：包含请求方法、请求目标（URL或URI）和HTTP协议版本。
- 请求头部：包含关于请求的附加信息，如Host、User-Agent、Content-Type等。
- 空行：请求头部和请求体之间用空行分隔。
- 请求体：可选，包含请求的数据，通常用于POST请求等需要传输数据的情况。

**响应报文：**

- 状态行：包含HTTP协议版本、状态码和状态信息。
- 响应头部：包含关于响应的附加信息，如Content-Type、Content-Length等。
- 空行：响应头部和响应体之间用空行分隔。

- 响应体：包含响应的数据，通常是服务器返回的HTML、JSON等内容。

### HTTP常用状态码

1xx:提示信息

2xx:成功

3xx:重定向 

301：永久重定向（说明请求的资源已经不存在了，需改用新的 URL 再次访问。）；302：临时重定向（说明请求的资源还在，但暂时需要用另一个 URL 来访问。）；

4xx:客户端错误 

404：无法找到此页面；405：请求的方法类型不支持；

5xx:服务器错误 

500：服务器内部出错。 502 Bad Gateway：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 504 Gateway Time-out：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器收到响应。

### HTTP常用请求类型

- GET：用于请求获取指定资源，通常用于获取数据。（**GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以可以进行缓存操作。）
- HEAD：类似于GET请求，但只返回资源的头部信息，用于获取资源的元数据而不获取实际内容。

- POST：用于向服务器提交数据，通常用于提交表单数据或进行资源的创建（因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。）。

- PUT：用于向服务器更新指定资源，通常用于更新已存在的资源。

- DELETE：用于请求服务器删除指定资源。

### HTTP长连接

HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应。

由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。

如果每次请求都要经历这样的过程：建立 TCP（三次挥手） -> 请求资源 -> 响应资源 -> 释放连接（四次挥手），那么此方式就是 **HTTP 短连接**。

HTTP 的 Keep-Alive 可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。

HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

### HTTP与HTTPS默认端口

http 是 80，https 默认是 443。

### HTTP1.1对请求做拆包

在HTTP/1.1中，请求的拆包是通过"Content-Length"头字段来进行的。该字段指示了请求正文的长度，服务器可以根据该长度来正确接收和解析请求。

### HTTP断点重传是什么？

断点续传是HTTP/1.1协议支持的特性。实现断点续传的功能，需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。

断点续传中4个HTTP头不可少的，**分别是Range头、Content-Range头、Accept-Ranges头、Content-Length头**。其中第一个Range头是客户端发过来的，后面3个头需要服务端发送给客户端。下面是它们的说明：

- **Accept-Ranges（bytes）：**这个值声明了可被接受的每一个范围请求, 大多数情况下是字节数 bytes
- **Range（ bytes=start-end）：**Range是浏览器告知服务器所需分部分内容范围的消息头。
- **Content-Length（bytes）**：响应报文主体部分的大小。
- **Content-Range (bytes = (start-end)/total)**：由服务器发送，且仅在相应部分内容（状态码206）时使用，它告诉客户端当前发送的数据片段在**整个资源**中的位置以及整个资源的总大小。

### HTTP为什么不安全？

HTTP 由于是明文传输，所以安全上存在以下三个风险：

- **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
- **篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
- **冒充风险**，比如冒充淘宝网站，用户钱容易没。

**HTTPS** 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：

- **信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。
- **校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。
- **身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

![image-20250506185742179](C:\Users\11965\Documents\八股\计算机网络.assets\image-20250506185742179.png)

### HTTP和HTTPS 的区别

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### HTTPS握手过程

传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件其实就是服务端的公钥，会在 TLS 握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。

在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。

 TLS 握手过程：一共经历了四次握手。

> TLS 第一次握手（客户端提供随机数字A TLS版本 加密方法  握手结束）

首先，由客户端向服务器发起加密通信请求。在这一步，客户端主要向服务器发送以下信息：

- 客户端支持的 TLS 协议版本，如 TLS 1.2 版本。
- 客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。
- 客户端支持的密码套件列表，如 RSA 加密算法。

> TLS 第二次握手（服务器 确定TLS版本 选定加密方法 提供数字证书（服务器公钥） 提供数字B 握手结束）

服务器收到客户端请求后，向客户端发出响应。服务器回应的内容有如下内容：

- 确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。
- 服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。
- 确认的密码套件列表，如 RSA 加密算法。
- 服务器的数字证书。

> TLS 第三次握手（客户端验证服务器数字证书 提供随机数字C 并用服务器的公钥加密 客户端使用ABC计算会话密钥 并提醒更改加密规格 握手结束（加密））

客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

- 一个随机数（pre-master key）。该随机数会被服务器公钥加密。
- 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
- 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

> TLS 第四次握手（用公钥解密数字C 服务器使用ABC计算会话密钥 提醒客户端更改加密规格 握手结束（加密））

服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

然后，向客户端发送最后的信息：

- 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
- 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

### HTTPS是如何防范中间人的攻击？

主要通过加密和身份校验机制来防范中间人攻击的:

- 加密：https 握手期间会通过非对称加密的方式来协商出对称加密密钥。
- 身份校验：服务器会向证书颁发机构申请数字证书，证书中包含了服务器的公钥和其他相关信息。当客户端与服务器建立连接时，服务器会将证书发送给客户端。客户端会验证证书的合法性，包括检查证书的有效期、颁发机构的信任等。如果验证通过，客户端会使用证书中的公钥来加密通信数据，并将加密后的数据发送给服务器，然后由服务端用私钥解密。

中间人攻击的关键在于攻击者冒充服务器与客户端建立连接，并同时与服务器建立连接。

但由于**攻击者无法获得服务器的私钥**，因此无法正确解密客户端发送的加密数据。同时，客户端会在**建立连接时验证服务器的证书**，如果证书验证失败或存在问题，客户端会发出警告或中止连接。

### HTTP 1.1和2.0的区别是什么？

HTTP/2 相比 HTTP/1.1 性能上的改进：

- **头部压缩**：HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。
- **二进制格式**：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**。这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这**增加了数据传输的效率**。
- **并发传输**：引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。解决了HTTP/1.1 队头阻塞的问题：
- **服务器主动推送资源**：HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以**主动**向客户端发送消息。

### HTTP进行TCP连接之后，在什么情况下会中断

- 当服务端或者客户端执行 close 系统调用的时候，会发送FIN报文，就会进行四次挥手的过程
- 当发送方发送了数据之后，接收方超过一段时间没有响应ACK报文，发送方重传数据达到最大次数的时候，就会断开TCP连接
- 当HTTP长时间没有进行请求和响应的时候，超过一定的时间，就会释放连接

### HTTP、SOCKET和TCP的区别

HTTP是应用层协议，定义了客户端和服务器之间交换的数据格式和规则；Socket是通信的一端，提供了网络通信的接口；TCP是传输层协议，负责在网络中建立可靠的数据传输连接。它们在网络通信中扮演不同的角色和层次。

- HTTP是一种用于传输超文本数据的应用层协议，用于在客户端和服务器之间传输和显示Web页面。
- **Socket（套接字）是一个应用程序编程接口（API），它位于应用程序层和传输层之间，允许应用程序层的进程使用传输层提供的服务（主要是TCP或UDP协议）来进行网络通信。**其在概念上和功能上紧密地**连接了应用程序层和传输层**，是实现网络通信编程的关键组件。
- TCP是一种面向连接的、可靠的传输层协议，负责在通信的两端之间建立可靠的数据传输连接。

### DNS的全称

DNS的全称是Domain Name System（域名系统），它是互联网中用于**将域名转换为对应IP地址**的分布式数据库系统。

 DNS中的域名用`.`分割 

 域名中越靠右层级越高 

![image-20250507132916674](C:\Users\11965\Documents\八股\计算机网络.assets\image-20250507132916674.png)

 如`map.server.com.` 

- 最后的`.`是根域名（被浏览器自动省略） 

-  `.com`是 顶级域 **顶级域DNS服务器所管理**其自身代表顶级域下的所有二级域名(`server.com`)

- `server`是一个二级域 与顶级域一起组成`server.com` 完整域名 ，这个完整域名其下的子域名都由 **权威DNS服务器所管理** 

- `www. / map. / tieba. 等`是子域名 由完整域名之下划分出来的部分 

 根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。 

 这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。 

 因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。

### DNS 域名解析的工作流程

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的**根域名服务器**：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能**指明一条道路**。
3. 根 DNS 收到来自本地 DNS 的请求后，**发现后置是 .com**，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com **顶级域名服务器**地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的**权威 DNS 服务器的地址**，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

### DNS的端口是多少？

默认53

### DNS的底层使用TCP还是UDP？

DNS 基于UDP协议实现，DNS使用UDP协议进行域名解析和数据传输。因为基于UDP实现DNS能够提供低延迟、简单快速、轻量级的特性，更适合DNS这种需要快速响应的域名解析服务。

- **低延迟：** UDP是一种无连接的协议，不需要在数据传输前建立连接，因此可以减少传输时延，适合DNS这种需要快速响应的应用场景。
- **简单快速：** UDP相比于TCP更简单，没有TCP的连接管理和流量控制机制，传输效率更高，适合DNS这种需要快速传输数据的场景。
- **轻量级**：UDP头部较小，占用较少的网络资源，对于小型请求和响应来说更加轻量级，适合DNS这种频繁且短小的数据交换。

尽管 UDP 存在丢包和数据包损坏的风险，但在 DNS 的设计中，这些风险是可以被容忍的。DNS 使用了一些机制来提高可靠性，例如查询超时重传、请求重试、缓存等，以确保数据传输的可靠性和正确性。

### HTTP到底是不是无状态的？

HTTP是无状态的，这意味着每个请求都是**独立**的，服务器不会在多个请求之间保留关于客户端状态的信息。在每个HTTP请求中，服务器不会记住之前的请求或会话状态，因此每个请求都是相互独立的。

虽然HTTP本身是无状态的，但可以通过一些机制来实现状态保持，其中最常见的方式是使用Cookie和Session来跟踪用户状态。通过在客户端存储会话信息或状态信息，服务器可以识别和跟踪特定用户的状态，以提供一定程度的状态保持功能。

### 携带Cookie的HTTP请求是有状态还是无状态的？Cookie是HTTP协议簇的一部分，那为什么还说HTTP是无状态的？

携带Cookie的HTTP请求实际上是可以在一定程度上实现状态保持的，因为Cookie是用来在客户端存储会话信息和状态信息的一种机制。当浏览器发送包含Cookie的HTTP请求时，服务器可以通过读取这些Cookie来识别用户、管理会话状态以及保持特定的用户状态。因此，可以说即使HTTP本身是无状态的协议，但通过Cookie的使用可以实现**一定程度的状态保持功能**。

HTTP被描述为“无状态”的主要原因是每个HTTP请求都是独立的，服务器并不保存关于客户端的状态信息，每个请求都需要提供足够的信息来理解请求的意图。这样的设计使得Web系统更具有规模化和简单性，但也导致了一些挑战，比如需要额外的机制来处理用户状态和会话管理。

虽然Cookie是HTTP协议簇的一部分，但是HTTP协议在设计初衷上仍然保持无状态特性，即每个请求都是相互独立的。使用Cookie只是在无状态协议下的一种补充机制，用于在客户端存储状态信息以实现状态保持。

### cookie和session有什么区别？

Cookie和Session都是Web开发中用于跟踪用户状态的技术，但它们在存储位置、数据容量、安全性以及生命周期等方面存在显著差异：

- **存储位置：**Cookie的数据存储在客户端（通常是浏览器）。当**浏览器向服务器发送请求**时，会自动附带Cookie中的数据。**Session的数据存储在服务器端**。服务器为每个用户分配一个唯一的Session ID，这个ID通常**通过Cookie或URL重写的方式发送给客户端**，客户端后续的请求会带上这个Session ID，服务器根据ID查找对应的Session数据。
- **数据容量：**单个Cookie的大小限制通常在4KB左右，而且大多数浏览器对每个域名的总Cookie数量也有限制。由于Session存储在服务器上，理论上不受数据大小的限制，主要受限于服务器的内存大小。
- **安全性：** **Cookie相对不安全，因为数据存储在客户端**，容易受到XSS（跨站脚本攻击）的威胁。不过，可以通过设置HttpOnly属性来防止JavaScript访问，减少XSS攻击的风险，但仍然可能受到CSRF（跨站请求伪造）的攻击。**Session通常认为比Cookie更安全，因为敏感数据存储在服务器端**。但仍然需要防范Session劫持（通过获取他人的Session ID）和会话固定攻击。
- **生命周期：** **Cookie可以设置过期时间，过期后自动删除**。也可以设置为会话Cookie，即浏览器关闭时自动删除。**Session在默认情况下，当用户关闭浏览器时，Session结束**。但服务器也可以设置Session的超时时间，超过这个时间未活动，Session也会失效。
- **性能：**使用Cookie时，因为数据随每个请求发送到服务器，可能会影响网络传输效率，尤其是在Cookie数据较大时。使用Session时，因为数据存储在服务器端，每次请求都需要查询服务器上的Session数据，这可能会增加服务器的负载，特别是在高并发场景下。

### token，session，cookie的区别？

- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session，依赖cookie。
- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。
- token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户，需要开发者手动添加。

### 如果客户端禁用了cookie，session还能用吗？

**默认情况下禁用 Cookie 后，Session 是无法正常使用的**，因为大多数 Web 服务器都是依赖于 Cookie 来传递 Session 的会话 ID 的。

客户端浏览器禁用 Cookie 时，服务器将无法把会话 ID 发送给客户端，客户端也无法在后续请求中携带会话 ID 返回给服务器，从而导致服务器无法识别用户会话。

但是，有几种方法可以绕过这个问题，尽管它们可能会引入额外的复杂性和/或降低用户体验：

1. **URL重写：**每当服务器响应需要保持状态的请求时，将Session ID附加到URL中作为参数。例如，原本的链接http://example.com/page变为http://example.com/page;jsessionid=XXXXXX，服务器端需要相应地解析 URL 来获取 Session ID，并维护用户的会话状态。这种方式的缺点是URL变得不那么整洁，且如果用户通过电子邮件或其他方式分享了这样的链接，可能导致Session ID的意外泄露。
2. **隐藏表单字段**：在每个需要Session信息的HTML表单中包含一个隐藏字段，用来存储Session ID。当表单提交时，Session ID随表单数据一起发送回服务器，服务器通过解析表单数据中的 Session ID 来获取用户的会话状态。这种方法仅适用于通过表单提交的交互模式，不适合链接点击或Ajax请求。

### 如果我把数据存储到 localStorage，和Cookie有什么区别？

- 存储容量: Cookie 的存储容量通常较小,每个 Cookie 的大小限制在几 KB 左右。而 LocalStorage 的存储容量通常较大,一般限制在几 MB 左右。因此,如果需要存储大量数据，LocalStorage 通常更适合;
- 数据发送: Cookie 在每次 HTTP 请求中都会自动发送到服务器,这使得 Cookie 适合用于在客户端和服务器之间传递数据。而 localStorage 的数据不会自动发送到服务器,它仅在浏览器端存储数据,因此 LocalStorage 适合用于在同一域名下的不同页面之间共享数据;
- 生命周期：Cookie 可以设置一个过期时间,使得数据在指定时间后自动过期。而 LocalStorage 的数据将永久存储在浏览器中,除非通过 JavaScript 代码手动删除;
- 安全性：Cookie 的安全性较低,因为 Cookie 在每次 HTTP 请求中都会自动发送到服务器,存在被窃取或篡改的风险。而 LocalStorage 的数据仅在浏览器端存储,不会自动发送到服务器,相对而言更安全一些。

### 什么数据应该存在到cookie，什么数据存放到 Localstorage

Cookie 适合用于在客户端和服务器之间传递数据、跨域访问和设置过期时间，而 LocalStorage 适合用于在同一域名下的不同页面之间共享数据、存储大量数据和永久存储数据。

### JWT 令牌和传统方式有什么区别？

- 无状态性：JWT是无状态的令牌，不需要在服务器端存储会话信息。相反，JWT令牌中包含了所有必要的信息，如用户身份、权限等。这使得JWT在分布式系统中更加适用，可以方便地进行扩展和跨域访问。
- 安全性：JWT使用密钥对令牌进行签名，确保令牌的完整性和真实性。**只有持有正确密钥的服务器才能对令牌进行验证和解析**。这种方式比传统的基于会话和Cookie的验证更加安全，有效防止了CSRF（跨站请求伪造）等攻击。
- 跨域支持：JWT令牌可以在不同域之间传递，适用于跨域访问的场景。通过在请求的头部或参数中携带JWT令牌，可以实现无需Cookie的跨域身份验证。

### JWT

**对于传统的基于Session的认证：**

- 客户端发送一个Session ID给服务器。
- 服务器需要在自己的存储（内存、数据库、缓存等）中查找这个Session ID，**核对**是否存在、是否过期、对应的用户信息是什么等等。这个过程依赖于服务器自己存储和维护的状态。

**对于JWT认证：**

- 客户端发送一个JWT给服务器。

- 服务器

  仍然需要进行严格的核对（验证），但核对的内容是JWT本身，而不是服务器自己存储的某个Session状态：

  1. **验证签名 (Signature Verification)：** 服务器必须使用预先配置好的密钥（对称加密的secret，或非对称加密的公钥）来验证JWT的签名是否正确。这是**最关键的一步**，确保JWT没有被篡改，并且确实是由合法的签发者签发的。如果签名无效，则请求立即被拒绝。

  2. 验证声明 (Claims Verification)：

     即使签名有效，服务器还需要检查JWT载荷（Payload）中的标准声明，例如：

     - `exp` (Expiration time)：令牌是否已过期？
     - `nbf` (Not Before time)：令牌是否已生效？
     - `iss` (Issuer)：签发者是否是预期的？
     - `aud` (Audience)：该令牌的接收方是否是当前服务？

  3. **提取并信任信息：** 只有当以上所有验证都通过后，服务器才能信任JWT载荷中包含的用户信息（如用户ID、角色等），并用这些信息进行后续的授权判断 。

### JWT 令牌都有哪些字段？

JWT令牌由三个部分组成：头部（Header）、载荷（Payload）和签名（Signature）。其中，头部和载荷均为JSON格式，使用Base64编码进行序列化，而签名部分是对头部、载荷和密钥进行签名后的结果。

### JWT 令牌为什么能解决集群部署，什么是集群部署？

在传统的基于会话和Cookie的身份验证方式中，会话信息通常存储在服务器的内存或数据库中。但在集群部署中，不同服务器之间没有共享的会话信息，这会导致用户在不同服务器之间切换时需要重新登录，或者需要引入额外的共享机制（如Redis），增加了复杂性和性能开销。

而JWT令牌通过在令牌中包含所有必要的身份验证和会话信息，使得服务器无需存储会话信息，从而解决了集群部署中的身份验证和会话管理问题。当用户进行登录认证后，服务器将生成一个JWT令牌并返回给客户端。客户端在后续的请求中携带该令牌，服务器可以通过对令牌进行验证和解析来获取用户身份和权限信息，而无需访问共享的会话存储。

由于JWT令牌是自包含的，服务器可以独立地对令牌进行验证，而不需要依赖其他服务器或共享存储。这使得集群中的每个服务器都可以独立处理请求，提高了系统的可伸缩性和容错性。

**集群部署**就是为了解决这些问题而采用的一种架构。简单来说，它是指： **将多台服务器（称为“节点”或“实例”）组合在一起，让它们协同工作，共同对外提供统一的服务，就像一个单一的、更强大的系统一样。**

**在集群环境中，用户的后续请求可能被负载均衡器分发到集群中的任何一台服务器。如果用户的第二个请求到了服务器B，而用户的Session信息存储在服务器A上，那么服务器B就无法识别这个用户，用户可能需要重新登录，或者会话信息丢失。**

### jwt的缺点是什么

JWT 一旦派发出去，在失效之前都是有效的，没办法即使撤销JWT。

要解决这个问题的话，得在业务层增加判断逻辑，比如增加**黑名单机制。**使用内存数据库比如 Redis 维护一个黑名单，如果想让某个 JWT 失效的话就直接将这个 JWT 加入到 **黑名单** 即可。然后，每次使用 JWT 进行请求的话都会先判断这个 JWT 是否存在于黑名单中。

### JWT 令牌如果泄露了，怎么解决，JWT是怎么做的？

- 及时失效令牌：当检测到JWT令牌泄露或存在风险时，可以立即将令牌标记为失效状态。服务器在接收到带有失效标记的令牌时，会拒绝对其进行任何操作，从而保护用户的身份和数据安全。
- 刷新令牌：JWT令牌通常具有一定的有效期，过期后需要重新获取新的令牌。当检测到令牌泄露时，可以主动刷新令牌，即重新生成一个新的令牌，并将旧令牌标记为失效状态。这样，即使泄露的令牌被恶意使用，也会很快失效，减少了被攻击者滥用的风险。
- 使用黑名单：服务器可以维护一个令牌的黑名单，将泄露的令牌添加到黑名单中。在接收到令牌时，先检查令牌是否在黑名单中，如果在则拒绝操作。这种方法需要服务器维护黑名单的状态，对性能有一定的影响，但可以有效地保护泄露的令牌不被滥用。

### 前端是如何存储JWT的？

JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案。互联网服务离不开用户认证。

一般流程如下：

1. 用户向服务器发送用户名和密码。
2. 服务器验证通过后，在当前对话（**session**）里面保存相关数据，比如用户角色、登录时间等等。
3. 服务器向用户返回一个 **session_id**，写入用户的 **Cookie**。
4. 用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。
5. 服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。

这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，**就要求 session 数据共享，每台服务器都能够读取 session**。

举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？

一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。

另一种方案是服务器索性不保存 session 数据了，**所有数据都保存在客户端，每次请求都发回服务器**。J**WT 就是这种方案的一个代表。**

客户端收到服务器返回的 JWT，**可以储存在 Local Storage 里面，也可以储存在Cookie里面，还可以存储在Session Storage里面。下面将说明存在上述各个地方的优劣势：**

> Local Storage（本地存储）

- **优点**：Local Storage 提供了较大的存储空间（一般为5MB），且不会随着HTTP请求一起发送到服务器，因此不会出现在HTTP缓存或日志中。
- **缺点**：存在XSS（跨站脚本攻击）的风险，恶意脚本可以通过JavaScript访问到存储在Local Storage中的JWT，从而盗取用户凭证。

> Session Storage（会话存储）

- **优点**：与Local Storage类似，但仅限于当前浏览器窗口或标签页，当窗口关闭后数据会被清除，这在一定程度上减少了数据泄露的风险。
- **缺点**：用户体验可能受影响，因为刷新页面或在新标签页打开相同应用时需要重新认证。

> Cookie

- **优点**：可以设置HttpOnly标志来防止通过JavaScript访问，减少XSS攻击的风险；可以利用Secure标志确保仅通过HTTPS发送，增加安全性。
- **缺点**：大小限制较小（通常4KB），并且每次HTTP请求都会携带Cookie，可能影响性能；设置不当可能会受到CSRF（跨站请求伪造）攻击。

### 为什么有HTTP协议了?还要用RPC?

- RPC 本质上不算是协议，而是一种调用方式，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，不一定非得基于 TCP 协议。
- 从发展历史来说，HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。
- RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 性能要更好，所以大部分公司内部都还在使用 RPC。
- HTTP/2.0在 HTTP/1.1的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。

### RPC

**Remote Procedure Call** RPC 是一种允许一台计算机（客户端）上的程序调用另一台计算机（服务器）上运行的程序中的一个函数或方法（也称为“过程”或“子程序”），就像调用本地的函数一样，而开发者不需要显式地编写复杂的网络通信代码。

**常见的RPC框架：**

- **gRPC:** 由Google开发，性能高，支持多种语言，使用Protocol Buffers作为接口定义语言和数据序列化格式。
- **Apache Thrift:** 由Facebook开发，也支持多种语言和多种序列化格式。
- **Dubbo:** 由阿里巴巴开源，主要用于Java。
- **JSON-RPC / XML-RPC:** 基于JSON或XML的轻量级RPC协议。

### HTTP长连接与WebSocket有什么区别？

- **全双工和半双工**：TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- **应用场景区别**：在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。

### 全双工与半双工

| 模式       | 数据方向         | 是否能同时收发 | 例子                     |
| :--------- | :--------------- | :------------- | :----------------------- |
| **单工**   | 单向             | 否             | 广播、电视、键盘         |
| **半双工** | 双向，但交替进行 | 否             | 对讲机、早期以太网集线器 |
| **全双工** | 双向，可同时进行 | 是             | 电话、现代交换式以太网   |

### Nginx有哪些负载均衡算法？

Nginx支持的负载均衡算法包括：

- **轮询**：按照顺序依次将请求分配给后端服务器。这种算法最简单，但是也无法处理某个节点变慢或者客户端操作有连续性的情况。
- **IP哈希**：根据客户端IP地址的哈希值来确定分配请求的后端服务器。适用于需要保持同一客户端的请求始终发送到同一台后端服务器的场景，如会话保持。
- **URL哈希**：按访问的URL的哈希结果来分配请求，使每个URL定向到一台后端服务器，可以进一步提高后端缓存服务器的效率。
- **最短响应时间**：按照后端服务器的响应时间来分配请求，响应时间短的优先分配。适用于后端服务器性能不均的场景，能够将请求发送到响应时间快的服务器，实现负载均衡。
- **加权轮询**：按照权重分配请求给后端服务器，权重越高的服务器获得更多的请求。适用于后端服务器性能不同的场景，可以根据服务器权重分配请求，提高高性能服务器的利用率。

### Nginx位于七层网络结构中的哪一层？

应用层，nginx 是七层负载均衡。

## 传输层